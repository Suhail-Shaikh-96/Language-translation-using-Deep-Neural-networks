{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEpBEjB5QGN9"
   },
   "source": [
    "#Sequence to Sequence Model for LanguageTranslation (40pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Kv6vIUyQP7E"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ddwgtrlkp_8o"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvE6BwUNvtPv"
   },
   "source": [
    "## Reading Sentence Translation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpsQ31FUq1tc"
   },
   "outputs": [],
   "source": [
    "data_file = \"/content/drive/My Drive/lang/mar-eng/mar.txt\"\n",
    "#data_file = \"/content/drive/My Drive/lang/spa-eng/spa.txt\"\n",
    "f = open(data_file, 'r')\n",
    "data_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSUHULPKuhVP"
   },
   "outputs": [],
   "source": [
    "language_x,language_y = [],[]\n",
    "for line in data_lines:\n",
    "  sentence = line.split(\"\\t\")\n",
    "  language_x.append(sentence[1].strip())\n",
    "  language_y.append(sentence[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WobMh-Fi03uT",
    "outputId": "e97889ac-e8ba-4d67-afa6-a29fddc7562a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('मी गरीब आहे.', \"I'm poor.\")"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_x[170],language_y[170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "7YUSd0D5XWVW",
    "outputId": "4b5d791b-545b-44ef-ce17-243c3bc26fad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40188"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(language_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epdJCGyvzTN_"
   },
   "source": [
    "## Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfzY6RVWyNij"
   },
   "outputs": [],
   "source": [
    "tokenizer_X = Tokenizer(oov_token=\"<unk>\",filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer_X.word_index['<pad>'] = 0\n",
    "tokenizer_X.index_word[0] = '<pad>'\n",
    "tokenizer_X.fit_on_texts(language_x)\n",
    "sequence_x = tokenizer_X.texts_to_sequences(language_x)\n",
    "\n",
    "tokenizer_y = Tokenizer(oov_token=\"<unk>\",filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer_y.word_index['<pad>'] = 0\n",
    "tokenizer_y.index_word[0] = '<pad>'\n",
    "tokenizer_y.fit_on_texts(language_y)\n",
    "sequence_y = tokenizer_y.texts_to_sequences(language_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "OUOEGbU20M0i",
    "outputId": "68bd3c17-a15e-417e-cf11-79ecc21e3e42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 657, 2], [29, 598])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_x[170],sequence_y[170]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgaAH4K0z0wQ"
   },
   "source": [
    "## Padding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YY-dWoHgy3Qu"
   },
   "outputs": [],
   "source": [
    "sequence_x_padded = pad_sequences(sequence_x, padding='post')\n",
    "sequence_y_padded = pad_sequences(sequence_y, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "5i-QyUOuyp0A",
    "outputId": "4377165d-153c-4109-9127-7b5959304a48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    8,  4119,    43,  5105,    91, 13517,    43,  4627,   264,\n",
       "         934,    63,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_x_padded[40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "mqauy9Ij2aat",
    "outputId": "3ead8a4e-27e2-49be-9655-dc273c9b8711"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36,  53, 655, 499,  19,   8, 323,  81, 588,  40,   8, 334,  81,\n",
       "       759,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_y_padded[40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nExSzSjz3AH"
   },
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "islnPsTtytSR"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( sequence_x_padded, sequence_y_padded, test_size=0.05, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "qTkA9pKs2fVa",
    "outputId": "30b0d1c5-2e87-4083-8bc7-2a2b38e45b42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3, 1038,  145, ...,    0,    0,    0],\n",
       "       [   6,  505,   37, ...,    0,    0,    0],\n",
       "       [  59,  782, 1970, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  40, 6279, 9100, ...,    0,    0,    0],\n",
       "       [   9,   62,  184, ...,    0,    0,    0],\n",
       "       [3862, 2932,    2, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "KkzZtdUx28tQ",
    "outputId": "e1d557b4-07e1-49bc-bd98-680a3aa60537"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,  77,   6, ...,   0,   0,   0],\n",
       "       [412,   2, 138, ...,   0,   0,   0],\n",
       "       [112,  71,  41, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 14, 305,  43, ...,   0,   0,   0],\n",
       "       [  4,  45,  56, ...,   0,   0,   0],\n",
       "       [ 39,   7,   8, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "uNiTksyW2-Ju",
    "outputId": "e1ff3b4c-5a8e-4077-c030-c97cd7cfe75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मी दुकानात गेलो\n",
      "i went to the shop\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_X.sequences_to_texts([X_train[0]])[0].replace(\"<unk>\",\"\").strip())\n",
    "print(tokenizer_y.sequences_to_texts([y_train[0]])[0].replace(\"<unk>\",\"\").strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5J47yso29BhD"
   },
   "source": [
    "## Creating LSTM model\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "broufTQ738fT",
    "outputId": "9eea67bf-4e26-465e-b37f-d559af2ff49a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size of original language:  13786\n",
      "Vocab size of translated language:  5857\n",
      "Vector length of each sentence in original language:  35\n",
      "Vector length of each sentence i translated language:  35\n"
     ]
    }
   ],
   "source": [
    "x_vocab_size = len(tokenizer_X.word_index) + 1\n",
    "y_vocab_size = len(tokenizer_y.word_index) + 1\n",
    "x_length = len(X_train[0])\n",
    "y_length = len(y_train[0])\n",
    "\n",
    "print(\"Vocab size of original language: \",x_vocab_size)\n",
    "print(\"Vocab size of translated language: \",y_vocab_size)\n",
    "print(\"Vector length of each sentence in original language: \",x_length)\n",
    "print(\"Vector length of each sentence i translated language: \",y_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrFoj4jr4ESw"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(x_vocab_size, 100, input_length=x_length, mask_zero=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(RepeatVector(y_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dense(y_vocab_size, activation='softmax'))\n",
    "rms = RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "ERg4XEnT4-3h",
    "outputId": "f732db35-1be9-4bc0-9999-82f054ba3fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 35, 100)           1378600   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 35, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 35, 100)           80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 35, 5857)          591557    \n",
      "=================================================================\n",
      "Total params: 2,130,957\n",
      "Trainable params: 2,130,957\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRf1SCI8-m17"
   },
   "source": [
    "## Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "Dz8GgSJLL5-U",
    "outputId": "74b85a9b-8263-47ab-e968-a40db214ef86"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "checkpoint_path = \"/content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlTh2cagRHSa"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XhtMzcdl-l-c",
    "outputId": "e37fb8d0-1b2d-4c03-aa4f-b4bd86443a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2770\n",
      "Epoch 00001: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 21s 39ms/step - loss: 0.2770 - val_loss: 0.5669\n",
      "Epoch 2/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2736\n",
      "Epoch 00002: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2736 - val_loss: 0.5710\n",
      "Epoch 3/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2703\n",
      "Epoch 00003: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 20s 36ms/step - loss: 0.2703 - val_loss: 0.5666\n",
      "Epoch 4/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2666\n",
      "Epoch 00004: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2666 - val_loss: 0.5712\n",
      "Epoch 5/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2639\n",
      "Epoch 00005: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2639 - val_loss: 0.5677\n",
      "Epoch 6/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2604\n",
      "Epoch 00006: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2604 - val_loss: 0.5703\n",
      "Epoch 7/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2571\n",
      "Epoch 00007: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2571 - val_loss: 0.5753\n",
      "Epoch 8/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2547\n",
      "Epoch 00008: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2547 - val_loss: 0.5728\n",
      "Epoch 9/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.2513\n",
      "Epoch 00009: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2513 - val_loss: 0.5743\n",
      "Epoch 10/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2482\n",
      "Epoch 00010: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 20s 36ms/step - loss: 0.2482 - val_loss: 0.5727\n",
      "Epoch 11/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2452\n",
      "Epoch 00011: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 20s 37ms/step - loss: 0.2452 - val_loss: 0.5748\n",
      "Epoch 12/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2424\n",
      "Epoch 00012: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2424 - val_loss: 0.5764\n",
      "Epoch 13/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2395\n",
      "Epoch 00013: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2395 - val_loss: 0.5753\n",
      "Epoch 14/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2361\n",
      "Epoch 00014: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2361 - val_loss: 0.5781\n",
      "Epoch 15/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2337\n",
      "Epoch 00015: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2337 - val_loss: 0.5776\n",
      "Epoch 16/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2308\n",
      "Epoch 00016: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2308 - val_loss: 0.5782\n",
      "Epoch 17/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2279\n",
      "Epoch 00017: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2279 - val_loss: 0.5774\n",
      "Epoch 18/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2253\n",
      "Epoch 00018: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2253 - val_loss: 0.5797\n",
      "Epoch 19/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2230\n",
      "Epoch 00019: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2230 - val_loss: 0.5862\n",
      "Epoch 20/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.2206\n",
      "Epoch 00020: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2206 - val_loss: 0.5823\n",
      "Epoch 21/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2182\n",
      "Epoch 00021: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2182 - val_loss: 0.5846\n",
      "Epoch 22/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2158\n",
      "Epoch 00022: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2158 - val_loss: 0.5872\n",
      "Epoch 23/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2136\n",
      "Epoch 00023: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2136 - val_loss: 0.5845\n",
      "Epoch 24/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2114\n",
      "Epoch 00024: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2114 - val_loss: 0.5885\n",
      "Epoch 25/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2093\n",
      "Epoch 00025: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2093 - val_loss: 0.5870\n",
      "Epoch 26/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.2069\n",
      "Epoch 00026: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 20s 37ms/step - loss: 0.2069 - val_loss: 0.5886\n",
      "Epoch 27/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2049\n",
      "Epoch 00027: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 20s 36ms/step - loss: 0.2049 - val_loss: 0.5917\n",
      "Epoch 28/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2028\n",
      "Epoch 00028: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2028 - val_loss: 0.5933\n",
      "Epoch 29/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.2006\n",
      "Epoch 00029: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.2006 - val_loss: 0.5936\n",
      "Epoch 30/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1986\n",
      "Epoch 00030: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1986 - val_loss: 0.5955\n",
      "Epoch 31/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1972\n",
      "Epoch 00031: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1972 - val_loss: 0.5957\n",
      "Epoch 32/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1953\n",
      "Epoch 00032: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.1953 - val_loss: 0.5980\n",
      "Epoch 33/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1936\n",
      "Epoch 00033: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1936 - val_loss: 0.5994\n",
      "Epoch 34/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00034: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1916 - val_loss: 0.6018\n",
      "Epoch 35/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1898\n",
      "Epoch 00035: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1898 - val_loss: 0.5999\n",
      "Epoch 36/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 00036: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.1881 - val_loss: 0.6015\n",
      "Epoch 37/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1865\n",
      "Epoch 00037: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1865 - val_loss: 0.6054\n",
      "Epoch 38/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1852\n",
      "Epoch 00038: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1852 - val_loss: 0.6096\n",
      "Epoch 39/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1835\n",
      "Epoch 00039: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1835 - val_loss: 0.6048\n",
      "Epoch 40/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.1817\n",
      "Epoch 00040: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1817 - val_loss: 0.6054\n",
      "Epoch 41/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.1805\n",
      "Epoch 00041: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1805 - val_loss: 0.6140\n",
      "Epoch 42/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.1786\n",
      "Epoch 00042: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1787 - val_loss: 0.6135\n",
      "Epoch 43/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1773\n",
      "Epoch 00043: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1773 - val_loss: 0.6152\n",
      "Epoch 44/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.1758\n",
      "Epoch 00044: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1758 - val_loss: 0.6128\n",
      "Epoch 45/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1749\n",
      "Epoch 00045: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1749 - val_loss: 0.6149\n",
      "Epoch 46/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1737\n",
      "Epoch 00046: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1737 - val_loss: 0.6181\n",
      "Epoch 47/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1725\n",
      "Epoch 00047: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 35ms/step - loss: 0.1725 - val_loss: 0.6199\n",
      "Epoch 48/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1709\n",
      "Epoch 00048: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 20s 37ms/step - loss: 0.1709 - val_loss: 0.6219\n",
      "Epoch 49/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.1697\n",
      "Epoch 00049: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 19s 36ms/step - loss: 0.1697 - val_loss: 0.6263\n",
      "Epoch 50/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.1683\n",
      "Epoch 00050: saving model to /content/drive/My Drive/lang/Checkpt_spa/cp.ckpt\n",
      "537/537 [==============================] - 20s 37ms/step - loss: 0.1682 - val_loss: 0.6212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=50, validation_split=0.1,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PjLaBU5AMJf"
   },
   "source": [
    "## Validating Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Z9NO4-Gectn"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PQBggsG-2n5"
   },
   "outputs": [],
   "source": [
    "y_pred_logits = model.predict(X_test[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1Zlc_mTBfeI"
   },
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for pred in y_pred_logits: \n",
    "  y_pred.append(np.argmax(pred,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC2Ajm62AGNa"
   },
   "outputs": [],
   "source": [
    "y_pred_text = tokenizer_y.sequences_to_texts(y_pred)\n",
    "y_test_text = tokenizer_y.sequences_to_texts(y_test[:200])\n",
    "X_test_text = tokenizer_X.sequences_to_texts(X_test[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "68F9ykZYfE_M",
    "outputId": "2aa97d46-d524-4b7b-933c-970a2e360e51"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'we made him made <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>'"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_text[145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "ZWDoExI6ARnb",
    "outputId": "faae663b-ad92-44e6-8436-b990c1ed235e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:  आम्ही त्यांना पळवून लावलं\n",
      "Predicted Sentence:  we made him made\n",
      "Actual Sentence:  we drove them out\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Sentence: \",X_test_text[145].replace(\"<unk>\",\"\").strip())\n",
    "print(\"Predicted Sentence: \",y_pred_text[145].replace(\"<unk>\",\"\").strip())\n",
    "print(\"Actual Sentence: \",y_test_text[145].replace(\"<unk>\",\"\").strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is0nxVZFp6NC"
   },
   "source": [
    "# PART 2 (Embedding using GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLed_YgA1yEy"
   },
   "outputs": [],
   "source": [
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split( sequence_y_padded, sequence_x_padded, test_size=0.05, random_state=12)\n",
    "tokenizer_X_g = tokenizer_y\n",
    "tokenizer_y_g = tokenizer_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "eouOAze34Bsn",
    "outputId": "b03c8dfb-a951-42a4-a373-a433d11a610b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size of original language:  5857\n",
      "Vocab size of translated language:  13786\n",
      "Vector length of each sentence in original language:  35\n",
      "Vector length of each sentence i translated language:  35\n"
     ]
    }
   ],
   "source": [
    "x_vocab_size_g = len(tokenizer_X_g.word_index) + 1\n",
    "y_vocab_size_g = len(tokenizer_y_g.word_index) + 1\n",
    "x_length_g = len(X_train_g[0])\n",
    "y_length_g = len(y_train_g[0])\n",
    "\n",
    "print(\"Vocab size of original language: \",x_vocab_size_g)\n",
    "print(\"Vocab size of translated language: \",y_vocab_size_g)\n",
    "print(\"Vector length of each sentence in original language: \",x_length_g)\n",
    "print(\"Vector length of each sentence i translated language: \",y_length_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4IUgx67yBMBm",
    "outputId": "93b8323c-c528-4c19-ef72-c0f90e4f231f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join('/content/drive/My Drive/glove.6B/', 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suptDo1E1Kb-"
   },
   "outputs": [],
   "source": [
    "word_i= tokenizer_X_g.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKZmCIpTqdiI"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_i) + 1, 100))\n",
    "for word, i in word_i.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-9jbvAx_vM_"
   },
   "source": [
    "## Model with GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilQmsD4_4mCt"
   },
   "outputs": [],
   "source": [
    "model_g = Sequential()\n",
    "model_g.add(Embedding(len(word_i) + 1,\n",
    "                            100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=x_length_g,\n",
    "                            trainable=False))\n",
    "model_g.add(LSTM(100))\n",
    "model_g.add(RepeatVector(y_length_g))\n",
    "model_g.add(LSTM(100, return_sequences=True))\n",
    "model_g.add(Dense(y_vocab_size_g, activation='softmax'))\n",
    "rms = RMSprop(lr=0.001)\n",
    "model_g.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "6rMcViRL6Lt1",
    "outputId": "6dbe7e89-e19c-463e-9359-3ab76998ec1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 35, 100)           585700    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 35, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 35, 100)           80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 35, 13786)         1392386   \n",
      "=================================================================\n",
      "Total params: 2,138,886\n",
      "Trainable params: 1,553,186\n",
      "Non-trainable params: 585,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4Vmo4e3R_Bx"
   },
   "outputs": [],
   "source": [
    "checkpoint_path_g = \"/content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\"\n",
    "checkpoint_dir_g = os.path.dirname(checkpoint_path_g)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback_g = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path_g,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "G3-G4-tOShhg",
    "outputId": "187d41bf-9a8f-489d-c809-69ede25589b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc5fe7ec9e8>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"/content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path_g)\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir_g)\n",
    "model_g.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MQS9zPSa5DYv",
    "outputId": "c15a8b8f-39c6-450c-89c7-5d06d4b762d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 1.2596\n",
      "Epoch 00001: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 33s 61ms/step - loss: 1.2596 - val_loss: 0.9618\n",
      "Epoch 2/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.9481\n",
      "Epoch 00002: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.9481 - val_loss: 0.9302\n",
      "Epoch 3/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.9294\n",
      "Epoch 00003: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.9294 - val_loss: 0.9381\n",
      "Epoch 4/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.9159\n",
      "Epoch 00004: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.9159 - val_loss: 0.9120\n",
      "Epoch 5/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.8971\n",
      "Epoch 00005: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.8971 - val_loss: 0.9041\n",
      "Epoch 6/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.8849\n",
      "Epoch 00006: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.8849 - val_loss: 0.8817\n",
      "Epoch 7/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.8656\n",
      "Epoch 00007: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.8656 - val_loss: 0.8742\n",
      "Epoch 8/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.8517\n",
      "Epoch 00008: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.8517 - val_loss: 0.8491\n",
      "Epoch 9/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.8504\n",
      "Epoch 00009: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.8504 - val_loss: 0.8470\n",
      "Epoch 10/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.8275\n",
      "Epoch 00010: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.8275 - val_loss: 0.8321\n",
      "Epoch 11/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.8163\n",
      "Epoch 00011: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.8163 - val_loss: 0.8260\n",
      "Epoch 12/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.8087\n",
      "Epoch 00012: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.8087 - val_loss: 0.8202\n",
      "Epoch 13/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.7951\n",
      "Epoch 00013: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7952 - val_loss: 0.8054\n",
      "Epoch 14/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7853\n",
      "Epoch 00014: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7853 - val_loss: 0.8014\n",
      "Epoch 15/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7800\n",
      "Epoch 00015: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7800 - val_loss: 0.7995\n",
      "Epoch 16/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7695\n",
      "Epoch 00016: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7695 - val_loss: 0.7857\n",
      "Epoch 17/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7587\n",
      "Epoch 00017: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7587 - val_loss: 0.7814\n",
      "Epoch 18/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7549\n",
      "Epoch 00018: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7549 - val_loss: 0.7825\n",
      "Epoch 19/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7414\n",
      "Epoch 00019: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7414 - val_loss: 0.7716\n",
      "Epoch 20/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7340\n",
      "Epoch 00020: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7340 - val_loss: 0.7624\n",
      "Epoch 21/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7363\n",
      "Epoch 00021: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7363 - val_loss: 0.7603\n",
      "Epoch 22/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7162\n",
      "Epoch 00022: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7162 - val_loss: 0.7481\n",
      "Epoch 23/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7090\n",
      "Epoch 00023: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7090 - val_loss: 0.7542\n",
      "Epoch 24/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.7049\n",
      "Epoch 00024: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7049 - val_loss: 0.7438\n",
      "Epoch 25/50\n",
      "536/537 [============================>.] - ETA: 0s - loss: 0.7015\n",
      "Epoch 00025: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.7015 - val_loss: 0.7466\n",
      "Epoch 26/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6986\n",
      "Epoch 00026: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6986 - val_loss: 0.7453\n",
      "Epoch 27/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6955\n",
      "Epoch 00027: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6955 - val_loss: 0.7446\n",
      "Epoch 28/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6943\n",
      "Epoch 00028: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6943 - val_loss: 0.7415\n",
      "Epoch 29/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6919\n",
      "Epoch 00029: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6919 - val_loss: 0.7408\n",
      "Epoch 30/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6899\n",
      "Epoch 00030: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6899 - val_loss: 0.7466\n",
      "Epoch 31/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6866\n",
      "Epoch 00031: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6866 - val_loss: 0.7408\n",
      "Epoch 32/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6832\n",
      "Epoch 00032: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6832 - val_loss: 0.7412\n",
      "Epoch 33/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6792\n",
      "Epoch 00033: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6792 - val_loss: 0.7374\n",
      "Epoch 34/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6660\n",
      "Epoch 00034: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6660 - val_loss: 0.7282\n",
      "Epoch 35/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6620\n",
      "Epoch 00035: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6620 - val_loss: 0.7272\n",
      "Epoch 36/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6594\n",
      "Epoch 00036: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6594 - val_loss: 0.7313\n",
      "Epoch 37/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6579\n",
      "Epoch 00037: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6579 - val_loss: 0.7270\n",
      "Epoch 38/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6555\n",
      "Epoch 00038: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6555 - val_loss: 0.7311\n",
      "Epoch 39/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6561\n",
      "Epoch 00039: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6561 - val_loss: 0.7325\n",
      "Epoch 40/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6513\n",
      "Epoch 00040: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6513 - val_loss: 0.7264\n",
      "Epoch 41/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6486\n",
      "Epoch 00041: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 60ms/step - loss: 0.6486 - val_loss: 0.7500\n",
      "Epoch 42/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6459\n",
      "Epoch 00042: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6459 - val_loss: 0.7272\n",
      "Epoch 43/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6429\n",
      "Epoch 00043: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6429 - val_loss: 0.7339\n",
      "Epoch 44/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6399\n",
      "Epoch 00044: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6399 - val_loss: 0.7196\n",
      "Epoch 45/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6367\n",
      "Epoch 00045: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6367 - val_loss: 0.7225\n",
      "Epoch 46/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6338\n",
      "Epoch 00046: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6338 - val_loss: 0.7175\n",
      "Epoch 47/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6308\n",
      "Epoch 00047: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6308 - val_loss: 0.7171\n",
      "Epoch 48/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6281\n",
      "Epoch 00048: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6281 - val_loss: 0.7165\n",
      "Epoch 49/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6252\n",
      "Epoch 00049: saving model to /content/drive/My Drive/lang/Checkpt_spa_g/cp.ckpt\n",
      "537/537 [==============================] - 32s 59ms/step - loss: 0.6252 - val_loss: 0.7130\n",
      "Epoch 50/50\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6221"
     ]
    }
   ],
   "source": [
    "history_g = model_g.fit(X_train_g, y_train_g, batch_size=64, epochs=50, validation_split=0.1,callbacks=[cp_callback_g])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW7HB9E9XNV5"
   },
   "source": [
    "## Model 2 prediciton (Eng -> Other lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhHMXBeL6PFh"
   },
   "outputs": [],
   "source": [
    "y_pred_logits_g = model_g.predict(X_test_g)\n",
    "\n",
    "y_pred_g=[]\n",
    "for pred_g in y_pred_logits_g: \n",
    "  y_pred_g.append(np.argmax(pred_g,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfuU6MO27nCA"
   },
   "outputs": [],
   "source": [
    "y_pred_text_g = tokenizer_y_g.sequences_to_texts(y_pred_g)\n",
    "y_test_text_g = tokenizer_y_g.sequences_to_texts(y_test_g)\n",
    "X_test_text_g = tokenizer_X_g.sequences_to_texts(X_test_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "B6PJzlvC71QB",
    "outputId": "23281543-b3bb-4a57-8c9c-d34b3d114ca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:  where's my mama\n",
      "Predicted Sentence:  माझी माझी कुठे आहे\n",
      "Actual Sentence:  माझी मम्मा कुठे आहे\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Sentence: \",X_test_text_g[256].replace(\"<unk>\",\"\").strip())\n",
    "print(\"Predicted Sentence: \",y_pred_text_g[256].replace(\"<unk>\",\"\").strip())\n",
    "print(\"Actual Sentence: \",y_test_text_g[256].replace(\"<unk>\",\"\").strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jraN0xIvTtCf"
   },
   "source": [
    "## Part 3: Testing on 5 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uILxK4Y_8BlN"
   },
   "outputs": [],
   "source": [
    "five_example_sentence= np.array([X_test_g[120],X_test_g[-2],X_test_g[256],X_test_g[123],X_test_g[456]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "PD4LfA0ESbAZ",
    "outputId": "b20c4611-1a15-4082-80b6-6ea65efc1c06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 35)"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_example_sentence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QQTz_LMTyX6"
   },
   "source": [
    "#### Prediction from Model 2 (Eng -> Chosen Lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJrr7t9qPxHQ"
   },
   "outputs": [],
   "source": [
    "y_pred_logits_model2 = model_g.predict(five_example_sentence)\n",
    "\n",
    "y_pred_model2 =[]\n",
    "for pred_model2  in y_pred_logits_model2 : \n",
    "  y_pred_model2.append(np.argmax(pred_model2 ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpiwYutPQW5J"
   },
   "outputs": [],
   "source": [
    "y_pred_text_model2  = tokenizer_y_g.sequences_to_texts(y_pred_model2)\n",
    "y_pred_text_model2_cleaned =[]\n",
    "for predicted in y_pred_text_model2:\n",
    "  y_pred_text_model2_cleaned.append(predicted.replace(\"<unk>\",\"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "Fbm4LPhOQklH",
    "outputId": "532dad63-5dea-47fb-a275-8ee9237a591e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['टॉमला येऊ', 'मला माझी पुस्तक दे', 'माझी माझी कुठे आहे', 'टॉम काहीतरी होता होता', 'टॉम आणि मेरी दोघेही आहेत']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_text_model2_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qRlME1iT5y3"
   },
   "source": [
    "#### Prediction from Model 1 (Chosen Lang -> Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8FPisxeTGPz"
   },
   "outputs": [],
   "source": [
    "model1_test_data_5 = pad_sequences(tokenizer_X.texts_to_sequences(y_pred_text_model2_cleaned),maxlen=X_test.shape[1],padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2M7FsGMQmcm"
   },
   "outputs": [],
   "source": [
    "y_pred_logits_model1 = model.predict(np.array(model1_test_data_5))\n",
    "\n",
    "y_pred_model1=[]\n",
    "for pred_model1 in y_pred_logits_model1: \n",
    "  y_pred_model1.append(np.argmax(pred_model1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P28MfGDLSDzN"
   },
   "outputs": [],
   "source": [
    "y_pred_text_model1 = tokenizer_y.sequences_to_texts(y_pred_model1)\n",
    "y_pred_text_model1_cleaned =[]\n",
    "for predicted_model1 in y_pred_text_model1:\n",
    "  y_pred_text_model1_cleaned.append(predicted_model1.replace(\"<unk>\",\"\").strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSYZGFI8WDRE"
   },
   "source": [
    "#### FINAL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8r7WxciEVnM3"
   },
   "outputs": [],
   "source": [
    "original_example_sentence = tokenizer_y.sequences_to_texts(five_example_sentence)\n",
    "original_cleaned=[]\n",
    "for original in original_example_sentence:\n",
    "  original_cleaned.append(original.replace(\"<unk>\",\"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "tOne-nZvS9ED",
    "outputId": "ba6c0431-c9dc-4b73-afa6-29f963745678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:\t\t let tom in\n",
      "Predicted Sentence By Model 2:\t टॉमला येऊ\n",
      "Predicted Sentence By Model 1:\t tom come come\n",
      "Original Sentence:\t\t give me my bag\n",
      "Predicted Sentence By Model 2:\t मला माझी पुस्तक दे\n",
      "Predicted Sentence By Model 1:\t give me the book\n",
      "Original Sentence:\t\t where's my mama\n",
      "Predicted Sentence By Model 2:\t माझी माझी कुठे आहे\n",
      "Predicted Sentence By Model 1:\t where's my tom\n",
      "Original Sentence:\t\t tom was hiding something\n",
      "Predicted Sentence By Model 2:\t टॉम काहीतरी होता होता\n",
      "Predicted Sentence By Model 1:\t tom was something\n",
      "Original Sentence:\t\t tom and mary both laughed\n",
      "Predicted Sentence By Model 2:\t टॉम आणि मेरी दोघेही आहेत\n",
      "Predicted Sentence By Model 1:\t tom and both both\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(five_example_sentence)):\n",
    "  print(\"Original Sentence:\\t\\t\",original_cleaned[i])\n",
    "  print(\"Predicted Sentence By Model 2:\\t\",y_pred_text_model2_cleaned[i])\n",
    "  print(\"Predicted Sentence By Model 1:\\t\",y_pred_text_model1_cleaned[i])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assg 3 Q 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
